
# ğŸ§  Ask the Web Assistant

A Streamlit app that takes a user's question, retrieves web content, and answers using a verified LLM pipeline powered by LangGraph and Gemini 2.0 Flash.

---

## âš™ï¸ Workflow

1. **User asks a question**
2. ğŸ” `get_links` â€“ Searches DuckDuckGo for relevant pages  
3. ğŸ§½ `scrape_web_data` â€“ Loads and cleans page content  
4. ğŸ§  `generate_answer` â€“ LLM answers using processed data  
5. âœ… `verify_citations` â€“ Ensures answer cites real sources  
6. ğŸ–¥ï¸ Streamlit UI displays answer and debug data  
7. ğŸ“Š Optional telemetry is recorded

---

## ğŸš€ Quick Start

```bash
git clone https://github.com/your-repo/ask-the-web-assistant.git
cd ask-the-web-assistant
pip install -r requirements.txt
streamlit run app.py
````

Or using Docker:

```bash
docker build -t ask-web . && docker run -p 8501:8501 ask-web
```

> âš ï¸ Ensure your `.env` has required API keys. See `.env.example`.

---

## ğŸ§± Architecture

![Flow diagram](image.png)

*LangGraph manages stateful steps like scraping, generating, and verifying.*

---

## ğŸ“ Prompt

**Instruction to LLM**:
*"You are a helpful assistant. Based on the following content, answer the user's question truthfully and cite the source."*

*This prompt keeps answers grounded and traceable.*

---

## âš ï¸ Limitations

* Citation checks are heuristic, not guaranteed
* Some sites block scraping
* LLMs may hallucinate if context is poor

---


